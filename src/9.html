<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>ğŸ‘ğŸ‘ğŸ‘</title>
    <style>
      body {
        margin: 0;
        height: 100vh;
        display: flex;
        align-items: center;
        background: lightblue;
      }
      #app {
        margin: auto;
      }
      #stream {
        visibility: hidden;
        position: absolute;
        top: 0;
        left: 0;
      }
      #overlay {
        position: absolute;
        border: 2px solid blue;
        height: 10px;
        width: 10px;
        transition: all 0.3s;
      }
    </style>
  </head>
  <body>
    <video id="stream" width="200" height="150" preload autoplay loop muted></video>
    <div id="overlay"></div>
    <canvas id="app"></canvas>
    <script src="assets/face-api.js"></script>
    <script>
      (async () => {
        const USE_FACE = true;
        const detectInterval = 100;

        const eyeColors = ['#a29bfe', '#74b9ff', '#ff7675', '#fab1a0', '#81ecec', '#55efc4'];
        const eyeSize = 120;
        const eyeMargin = 20;
        const mouseDepth = 200;
        const maxDistance = 400;

        const irisRadius = 3/10 * eyeSize;
        const pupilRadius = 1/6 * eyeSize;
        const hightlightRadius = 1/16 * eyeSize;

        const streamElement = document.getElementById('stream');
        const overlay = document.getElementById('overlay');

        await faceapi.nets.tinyFaceDetector.loadFromUri('assets');
        const detector = new faceapi.TinyFaceDetectorOptions({size: 416});
        let stream;
        const radius = eyeSize/2;
        let height = 0;
        let width = 0;
        let nX;
        let nY;
        let colors = [];
        let dest = {
          x: 0,
          y: 0,
          z: 0
        };
        let started = false;

        let canvas = document.getElementById('app');
        let ctx = canvas.getContext('2d');

        computeSize();
        window.addEventListener('resize', computeSize);
        window.addEventListener('mousemove', mouseEvent);
        window.addEventListener('dragover', mouseEvent);
        window.addEventListener('touchstart', e => {
          mouseEvent(e.changedTouches[0])
        });
        window.addEventListener('touchmove', e => {
          mouseEvent(e.changedTouches[0])
        });


        // App fns
        async function initVideo() {
          try {
            stream = await navigator.mediaDevices.getUserMedia({video: true});
          } catch (err) {
            throw new Error('Unable to get webcam');
          }
          streamElement.srcObject = stream;
          streamElement.addEventListener('playing', streamStart);
        }
        function streamStart() {
          if(started) console.error('Playing, but already started!');
          started = true;
          detect();
        }
        function mouseEvent(e) {
          if(!USE_FACE) {
            dest.x = e.clientX;
            dest.y = e.clientY;
            dest.z = mouseDepth;
          }
        }
        function computeSize() {
          let docHeight = document.body.offsetHeight;
          let docWidth = document.body.offsetWidth;

          nX = Math.floor((docWidth - eyeMargin)/(eyeSize + eyeMargin));
          nY = Math.floor((docHeight - eyeMargin)/(eyeSize + eyeMargin));

          height = canvas.height = eyeMargin + (eyeSize + eyeMargin) * nY;
          width = canvas.width =  eyeMargin + (eyeSize + eyeMargin) * nX;
          makeColors();
        }
        function makeColors() {
          colors = Array.from({length: nY}).map((r, i) => {
            return Array.from({length: nX}, (v, i) => pickRandom(eyeColors))
          });
        }
        // Generic Utils
        function pickRandom(arr) {
          return arr[Math.floor(Math.random() * arr.length)];
        }
        function pythagoras3d(x, y, z) {
          return Math.sqrt(x ** 2 + y ** 2 + z ** 2)
        }
        function clamp(val, min, max) {
          return Math.min(max, Math.max(min, val));
        }

        function render() {
          ctx.clearRect(0, 0, width, height);
          for(let y = 0; y < nY; y++) {
            for(let x = 0; x < nX; x++) {
              renderEye(x, y);
            }
          }
          requestAnimationFrame(render)
        }

        function renderEye(x, y) {
          let eyeX = x * (eyeSize + eyeMargin) + eyeMargin + radius; // center points
          let eyeY = y * (eyeSize + eyeMargin) + eyeMargin + radius;

          let deltaX = clamp(dest.x - eyeX, -maxDistance, maxDistance);
          let deltaY = clamp(dest.y - eyeY, -maxDistance, maxDistance);

          let dist = pythagoras3d(deltaX, deltaY, dest.z);
          let ratio = (radius/1.2)/dist;

          let offsetX = deltaX * ratio;
          let offsetY = deltaY * ratio;

          // clip to eye area
          ctx.save();
          ctx.beginPath();
          ctx.ellipse(eyeX, eyeY, radius, radius, 0, 0, 2 * Math.PI);
          ctx.clip();

          // eye
          ctx.fillStyle = 'white';
          ctx.beginPath();
          ctx.ellipse(eyeX, eyeY, radius, radius, 0, 0, 2 * Math.PI);
          ctx.fill();

          // iris
          ctx.fillStyle = colors[y][x];
          ctx.beginPath();
          ctx.ellipse(eyeX + offsetX, eyeY + offsetY,
            irisRadius - Math.abs(3 * offsetX/radius), // width
            irisRadius - Math.abs(3 * offsetY/radius), // height
            0, 0, 2 * Math.PI);
          ctx.fill();

          // pupil
          ctx.fillStyle = 'black';
          ctx.beginPath();
          ctx.ellipse(eyeX + (offsetX * 1.15), eyeY + (offsetY * 1.15),
            pupilRadius - Math.abs(5 * offsetX/radius), // width
            pupilRadius - Math.abs(5 * offsetY/radius), // height
            0, 0, 2 * Math.PI);
          ctx.fill();

          // highlight
          ctx.fillStyle = 'white';
          ctx.beginPath();
          ctx.ellipse(eyeX + (offsetX * 1.2) + 15, eyeY + (offsetY * 1.2) - 15, hightlightRadius, hightlightRadius, 0, 0, 2 * Math.PI);
          ctx.fill();

          ctx.restore();
        }
        async function detect() {
          const detection = await faceapi.detectSingleFace(streamElement, detector);
          if(detection) {
            // console.log(detection.box)
            let {box} = detection;
            let scale = streamElement.width / streamElement.videoWidth;
            overlay.style.top = box.y * scale + 'px';
            overlay.style.left = box.x * scale + 'px';
            overlay.style.height = box.height * scale + 'px';
            overlay.style.width = box.width * scale + 'px';
          }
          if(USE_FACE && detection)
            transformDetection(detection);
          setTimeout(detect, detectInterval);
        }
        function transformDetection({box}) {
          let scaleX = width / streamElement.videoWidth;
          let scaleY = height / streamElement.videoHeight;
          let boxCenterX = box.x + box.width / 2;
          let boxCenterY = box.y + box.height / 2;
          let scaledX = width - (scaleX * boxCenterX); // Flip position, mirror webcam
          let scaledY = boxCenterY * scaleY;
          let fromCenterX = scaledX - width/2;
          let fromCenterY = scaledY - height/2;
          dest = {
            x: width/2 + fromCenterX * 0.8,
            y: height/2 + fromCenterY * 1.5,
            z: 80000 / box.width
          };
        }

        render();
        initVideo();
      })();
    </script>
  </body>
</html>
